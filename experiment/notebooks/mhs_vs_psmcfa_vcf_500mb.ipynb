{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSMC-RS: MHS vs PSMCFA vs VCF (500Mb, 4 demographic models)\n",
    "\n",
    "This notebook:\n",
    "1. Simulates **the same diploid genome** with `msprime` for 4 models (`constant`, `bottleneck`, `expansion`, `zigzag`).\n",
    "2. Serializes each simulation into **three** input formats:\n",
    "   - `psmcfa`\n",
    "   - official `multihetsep/mhs` (`chrom pos nr_called alleles`)\n",
    "   - `vcf`\n",
    "3. Runs `psmc-rs` on all formats with matched inference settings.\n",
    "4. Plots and quantifies differences (`MHS` / `VCF` vs `PSMCFA`) and recovery vs true curve.\n",
    "\n",
    "> Default length is **500,000,000 bp** per model. You can override via `SIM_LENGTH_BP` env var before launching Jupyter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import platform\n",
    "import shlex\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as pe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import msprime\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / 'Cargo.toml').exists() and (p / 'src').exists():\n",
    "            return p\n",
    "    raise RuntimeError(f'Cannot locate psmc-rs root from {start}')\n",
    "\n",
    "\n",
    "ROOT = find_repo_root(Path.cwd().resolve())\n",
    "\n",
    "EXP_DIR = ROOT / 'experiment' / 'runs' / 'format_consistency'\n",
    "INPUT_DIR = EXP_DIR / 'inputs'\n",
    "OUTPUT_DIR = EXP_DIR / 'outputs'\n",
    "for d in (EXP_DIR, INPUT_DIR, OUTPUT_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PSMC_RS_BIN = Path(os.environ.get('PSMC_RS_BIN', str(ROOT / 'target' / 'release' / 'psmc-rs')))\n",
    "\n",
    "# Core run config\n",
    "SIM_LENGTH_BP = int(os.environ.get('SIM_LENGTH_BP', '500000000'))\n",
    "WINDOW_BP = int(os.environ.get('WINDOW_BP', '100'))\n",
    "MU = float(os.environ.get('MU', '2.5e-8'))\n",
    "RECOMB = float(os.environ.get('RECOMB', '1.25e-8'))\n",
    "GEN_YEARS = float(os.environ.get('GEN_YEARS', '25'))\n",
    "\n",
    "N_ITER = int(os.environ.get('N_ITER', '20'))\n",
    "T_MAX = float(os.environ.get('T_MAX', '15'))\n",
    "N_STEPS = int(os.environ.get('N_STEPS', '64'))\n",
    "PATTERN = os.environ.get('PATTERN', '4+25*2+4+6')\n",
    "BATCH_SIZE = int(os.environ.get('BATCH_SIZE', '300000'))\n",
    "THREADS = int(os.environ.get('THREADS', '1'))\n",
    "SMOOTH_LAMBDA = float(os.environ.get('SMOOTH_LAMBDA', '1e-3'))\n",
    "FORCE_SIM = os.environ.get('FORCE_SIM', '1').strip() != '0'\n",
    "\n",
    "print(f'ROOT={ROOT}')\n",
    "print(f'Python={sys.executable}')\n",
    "print(f'Platform={platform.platform()}')\n",
    "print(f'msprime={msprime.__version__}')\n",
    "print(f'PSMC_RS_BIN={PSMC_RS_BIN}')\n",
    "print(f'SIM_LENGTH_BP={SIM_LENGTH_BP:,}, WINDOW_BP={WINDOW_BP}, symbols={math.ceil(SIM_LENGTH_BP / WINDOW_BP):,}')\n",
    "print(f'MU={MU:.3e}, RECOMB={RECOMB:.3e}, GEN_YEARS={GEN_YEARS}')\n",
    "print(f'N_ITER={N_ITER}, T_MAX={T_MAX}, N_STEPS={N_STEPS}, PATTERN={PATTERN}')\n",
    "print(f'BATCH_SIZE={BATCH_SIZE}, THREADS={THREADS}, SMOOTH_LAMBDA={SMOOTH_LAMBDA}')\n",
    "print(f'FORCE_SIM={FORCE_SIM} (set FORCE_SIM=0 to reuse existing inputs)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cmd(cmd: List[str], cwd: Optional[Path] = None, check: bool = True):\n",
    "    start = time.perf_counter()\n",
    "    proc = subprocess.run(\n",
    "        cmd,\n",
    "        cwd=str(cwd) if cwd is not None else None,\n",
    "        text=True,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "    )\n",
    "    dt = time.perf_counter() - start\n",
    "    rec = {\n",
    "        'cmd': ' '.join(shlex.quote(x) for x in cmd),\n",
    "        'returncode': proc.returncode,\n",
    "        'stdout': proc.stdout,\n",
    "        'stderr': proc.stderr,\n",
    "        'wall_sec': dt,\n",
    "    }\n",
    "    if check and proc.returncode != 0:\n",
    "        print(rec['cmd'])\n",
    "        print('--- stdout ---')\n",
    "        print(proc.stdout)\n",
    "        print('--- stderr ---')\n",
    "        print(proc.stderr)\n",
    "        raise RuntimeError(f'command failed: rc={proc.returncode}')\n",
    "    return rec\n",
    "\n",
    "\n",
    "def ensure_psmc_rs_release_binary() -> Path:\n",
    "    if PSMC_RS_BIN.exists():\n",
    "        return PSMC_RS_BIN\n",
    "    print('[build] cargo build --release')\n",
    "    run_cmd(['cargo', 'build', '--release'], cwd=ROOT)\n",
    "    if not PSMC_RS_BIN.exists():\n",
    "        raise FileNotFoundError(f'psmc-rs binary not found after build: {PSMC_RS_BIN}')\n",
    "    return PSMC_RS_BIN\n",
    "\n",
    "\n",
    "ensure_psmc_rs_release_binary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coalescent_events_to_generations(n0: float, events_4n0: List[Tuple[float, float]]) -> List[Tuple[float, float]]:\n",
    "    return [(t4 * 4.0 * n0, ratio * n0) for (t4, ratio) in events_4n0]\n",
    "\n",
    "\n",
    "MODELS: Dict[str, Dict] = {\n",
    "    'constant': {\n",
    "        'title': 'Constant',\n",
    "        'n0': 10_000.0,\n",
    "        'events_gen': [],\n",
    "        'seed': 42,\n",
    "    },\n",
    "    'bottleneck': {\n",
    "        'title': 'Bottleneck',\n",
    "        'n0': 20_000.0,\n",
    "        'events_gen': coalescent_events_to_generations(20_000.0, [\n",
    "            (0.01, 0.05),\n",
    "            (0.015, 0.5),\n",
    "            (0.05, 0.25),\n",
    "            (0.5, 0.5),\n",
    "        ]),\n",
    "        'seed': 43,\n",
    "    },\n",
    "    'expansion': {\n",
    "        'title': 'Expansion',\n",
    "        'n0': 10_000.0,\n",
    "        'events_gen': coalescent_events_to_generations(10_000.0, [\n",
    "            (0.01, 0.1),\n",
    "            (0.06, 1.0),\n",
    "            (0.2, 0.5),\n",
    "            (1.0, 1.0),\n",
    "            (2.0, 2.0),\n",
    "        ]),\n",
    "        'seed': 44,\n",
    "    },\n",
    "    'zigzag': {\n",
    "        'title': 'Zigzag',\n",
    "        'n0': 1_000.0,\n",
    "        'events_gen': coalescent_events_to_generations(1_000.0, [\n",
    "            (0.1, 5.0),\n",
    "            (0.6, 20.0),\n",
    "            (2.0, 5.0),\n",
    "            (10.0, 10.0),\n",
    "            (20.0, 5.0),\n",
    "        ]),\n",
    "        'seed': 45,\n",
    "    },\n",
    "}\n",
    "MODEL_ORDER = ['constant', 'bottleneck', 'expansion', 'zigzag']\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelPaths:\n",
    "    psmcfa: Path\n",
    "    mhs: Path\n",
    "    vcf: Path\n",
    "    rust_psmcfa_json: Path\n",
    "    rust_mhs_json: Path\n",
    "    rust_vcf_json: Path\n",
    "\n",
    "\n",
    "def model_paths(key: str) -> ModelPaths:\n",
    "    return ModelPaths(\n",
    "        psmcfa=INPUT_DIR / f'{key}.psmcfa',\n",
    "        mhs=INPUT_DIR / f'{key}.multihetsep',\n",
    "        vcf=INPUT_DIR / f'{key}.vcf',\n",
    "        rust_psmcfa_json=OUTPUT_DIR / f'{key}.psmcfa.rust.json',\n",
    "        rust_mhs_json=OUTPUT_DIR / f'{key}.mhs.rust.json',\n",
    "        rust_vcf_json=OUTPUT_DIR / f'{key}.vcf.rust.json',\n",
    "    )\n",
    "\n",
    "\n",
    "def true_curve_for_model(key: str):\n",
    "    spec = MODELS[key]\n",
    "    xs = [1e3]\n",
    "    ys = [spec['n0']]\n",
    "    for t_gen, ne in sorted(spec['events_gen'], key=lambda x: x[0]):\n",
    "        xs.append(max(1e3, t_gen * GEN_YEARS))\n",
    "        ys.append(ne)\n",
    "    xs.append(1e8)\n",
    "    ys.append(ys[-1])\n",
    "    return np.array(xs, dtype=float), np.array(ys, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_demography(n0: float, events_gen: List[Tuple[float, float]]) -> msprime.Demography:\n",
    "    dem = msprime.Demography()\n",
    "    dem.add_population(name='pop0', initial_size=float(n0))\n",
    "    for t, ne in sorted(events_gen, key=lambda x: x[0]):\n",
    "        dem.add_population_parameters_change(time=float(t), population='pop0', initial_size=float(ne))\n",
    "    return dem\n",
    "\n",
    "\n",
    "def write_psmcfa(path: Path, seq: str, header: str = 'chr1'):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with path.open('w', encoding='utf-8') as f:\n",
    "        f.write(f'> {header}\\n')\n",
    "        wrap = 60\n",
    "        for i in range(0, len(seq), wrap):\n",
    "            f.write(seq[i:i+wrap] + '\\n')\n",
    "\n",
    "\n",
    "def simulate_model_to_three_formats(key: str, force: bool = False):\n",
    "    spec = MODELS[key]\n",
    "    p = model_paths(key)\n",
    "    if (not force) and p.psmcfa.exists() and p.mhs.exists() and p.vcf.exists():\n",
    "        return {\n",
    "            'model': key,\n",
    "            'sim_skipped': True,\n",
    "            'psmcfa': str(p.psmcfa),\n",
    "            'mhs': str(p.mhs),\n",
    "            'vcf': str(p.vcf),\n",
    "        }\n",
    "\n",
    "    dem = build_demography(spec['n0'], spec['events_gen'])\n",
    "    ts = msprime.sim_ancestry(\n",
    "        samples={'pop0': 1},\n",
    "        ploidy=2,\n",
    "        demography=dem,\n",
    "        sequence_length=float(SIM_LENGTH_BP),\n",
    "        recombination_rate=float(RECOMB),\n",
    "        random_seed=int(spec['seed']),\n",
    "    )\n",
    "    mts = msprime.sim_mutations(\n",
    "        ts,\n",
    "        rate=float(MU),\n",
    "        random_seed=int(spec['seed']) + 1,\n",
    "    )\n",
    "\n",
    "    n_bins = math.ceil(SIM_LENGTH_BP / WINDOW_BP)\n",
    "    has_het = np.zeros(n_bins, dtype=bool)\n",
    "\n",
    "    mhs_rows = []\n",
    "    prev_emit_pos = 0\n",
    "    het_sites = 0\n",
    "    all_sites = 0\n",
    "\n",
    "    for var in mts.variants():\n",
    "        pos = int(var.site.position) + 1  # 1-based\n",
    "        if pos < 1 or pos > SIM_LENGTH_BP:\n",
    "            continue\n",
    "        all_sites += 1\n",
    "\n",
    "        g0 = int(var.genotypes[0])\n",
    "        g1 = int(var.genotypes[1])\n",
    "        a0 = var.alleles[g0]\n",
    "        a1 = var.alleles[g1]\n",
    "\n",
    "        if a0 != a1:\n",
    "            het_sites += 1\n",
    "            idx = (pos - 1) // WINDOW_BP\n",
    "            has_het[idx] = True\n",
    "\n",
    "            nr_called = pos - prev_emit_pos\n",
    "            if nr_called <= 0:\n",
    "                continue\n",
    "            mhs_rows.append((pos, nr_called, f'{a0}{a1}'))\n",
    "            prev_emit_pos = pos\n",
    "\n",
    "    seq = ''.join('K' if x else 'T' for x in has_het)\n",
    "    write_psmcfa(p.psmcfa, seq, header='chr1')\n",
    "\n",
    "    p.mhs.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with p.mhs.open('w', encoding='utf-8') as f:\n",
    "        for pos, nr_called, alleles in mhs_rows:\n",
    "            f.write(f'chr1\\t{pos}\\t{nr_called}\\t{alleles}\\n')\n",
    "\n",
    "    with p.vcf.open('w', encoding='utf-8') as f:\n",
    "        mts.write_vcf(f, contig_id='chr1')\n",
    "\n",
    "    return {\n",
    "        'model': key,\n",
    "        'sim_skipped': False,\n",
    "        'psmcfa': str(p.psmcfa),\n",
    "        'mhs': str(p.mhs),\n",
    "        'vcf': str(p.vcf),\n",
    "        'all_sites': all_sites,\n",
    "        'het_sites': het_sites,\n",
    "        'mhs_rows': len(mhs_rows),\n",
    "        'psmcfa_symbols': len(seq),\n",
    "        'psmcfa_mb': p.psmcfa.stat().st_size / 1e6,\n",
    "        'mhs_mb': p.mhs.stat().st_size / 1e6,\n",
    "        'vcf_mb': p.vcf.stat().st_size / 1e6,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_rows = []\n",
    "for key in MODEL_ORDER:\n",
    "    print(f'[simulate] {key} (length={SIM_LENGTH_BP:,} bp)')\n",
    "    sim_rows.append(simulate_model_to_three_formats(key, force=FORCE_SIM))\n",
    "\n",
    "sim_df = pd.DataFrame(sim_rows)\n",
    "display(sim_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_psmc_rs(input_path: Path, input_format: str, output_json: Path):\n",
    "    cmd = [\n",
    "        str(PSMC_RS_BIN),\n",
    "        str(input_path),\n",
    "        str(output_json),\n",
    "        str(N_ITER),\n",
    "        '--input-format', input_format,\n",
    "        '--t-max', str(T_MAX),\n",
    "        '--n-steps', str(N_STEPS),\n",
    "        '--pattern', PATTERN,\n",
    "        '--mu', str(MU),\n",
    "        '--smooth-lambda', str(SMOOTH_LAMBDA),\n",
    "        '--batch-size', str(BATCH_SIZE),\n",
    "        '--threads', str(THREADS),\n",
    "        '--no-progress',\n",
    "    ]\n",
    "    if input_format in ('mhs', 'vcf'):\n",
    "        cmd += ['--mhs-bin-size', str(WINDOW_BP)]\n",
    "    return run_cmd(cmd, cwd=ROOT)\n",
    "\n",
    "run_rows = []\n",
    "for key in MODEL_ORDER:\n",
    "    p = model_paths(key)\n",
    "\n",
    "    print(f'[run] {key} / psmcfa')\n",
    "    r1 = run_psmc_rs(p.psmcfa, 'psmcfa', p.rust_psmcfa_json)\n",
    "    run_rows.append({\n",
    "        'model': key,\n",
    "        'format': 'psmcfa',\n",
    "        'wall_sec': r1['wall_sec'],\n",
    "        'output_json': str(p.rust_psmcfa_json),\n",
    "    })\n",
    "\n",
    "    print(f'[run] {key} / mhs')\n",
    "    r2 = run_psmc_rs(p.mhs, 'mhs', p.rust_mhs_json)\n",
    "    run_rows.append({\n",
    "        'model': key,\n",
    "        'format': 'mhs',\n",
    "        'wall_sec': r2['wall_sec'],\n",
    "        'output_json': str(p.rust_mhs_json),\n",
    "    })\n",
    "\n",
    "    print(f'[run] {key} / vcf')\n",
    "    r3 = run_psmc_rs(p.vcf, 'vcf', p.rust_vcf_json)\n",
    "    run_rows.append({\n",
    "        'model': key,\n",
    "        'format': 'vcf',\n",
    "        'wall_sec': r3['wall_sec'],\n",
    "        'output_json': str(p.rust_vcf_json),\n",
    "    })\n",
    "\n",
    "run_df = pd.DataFrame(run_rows)\n",
    "display(run_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pattern_spec(pattern):\n",
    "    if pattern is None:\n",
    "        return None\n",
    "    out = []\n",
    "    for part in str(pattern).split('+'):\n",
    "        part = part.strip()\n",
    "        if not part:\n",
    "            continue\n",
    "        if '*' in part:\n",
    "            a, b = part.split('*', 1)\n",
    "            nr = int(a.strip())\n",
    "            gl = int(b.strip())\n",
    "        else:\n",
    "            nr = 1\n",
    "            gl = int(part)\n",
    "        if nr <= 0 or gl <= 0:\n",
    "            raise ValueError(f'invalid pattern token: {part}')\n",
    "        out.append((nr, gl))\n",
    "    return out if out else None\n",
    "\n",
    "\n",
    "def parse_pattern_spec_legacy(pattern):\n",
    "    if pattern is None:\n",
    "        return None\n",
    "    out = []\n",
    "    for part in str(pattern).split('+'):\n",
    "        part = part.strip()\n",
    "        if not part:\n",
    "            continue\n",
    "        if '*' in part:\n",
    "            a, b = part.split('*', 1)\n",
    "            ts = int(a.strip())\n",
    "            gs = int(b.strip())\n",
    "        else:\n",
    "            ts = int(part)\n",
    "            gs = 1\n",
    "        if ts <= 0 or gs <= 0:\n",
    "            raise ValueError(f'invalid legacy token: {part}')\n",
    "        out.append((ts, gs))\n",
    "    return out if out else None\n",
    "\n",
    "\n",
    "def expand_lam(lam_grouped, n_steps, pattern_spec, pattern_raw=None):\n",
    "    lam_grouped = list(map(float, lam_grouped))\n",
    "    if pattern_spec is None:\n",
    "        if len(lam_grouped) != n_steps + 1:\n",
    "            raise ValueError(f'lam length {len(lam_grouped)} != n_steps+1 ({n_steps+1})')\n",
    "        return lam_grouped\n",
    "\n",
    "    expected_c = sum(nr for nr, _ in pattern_spec)\n",
    "    if len(lam_grouped) == expected_c:\n",
    "        lam = []\n",
    "        idx = 0\n",
    "        for nr, gl in pattern_spec:\n",
    "            for _ in range(nr):\n",
    "                lam.extend([lam_grouped[idx]] * gl)\n",
    "                idx += 1\n",
    "        if len(lam) != n_steps + 1:\n",
    "            raise ValueError(f'expanded lam length {len(lam)} != n_steps+1 ({n_steps+1})')\n",
    "        return lam\n",
    "\n",
    "    legacy_spec = parse_pattern_spec_legacy(pattern_raw)\n",
    "    expected_legacy = sum(ts for ts, _ in legacy_spec) + 1 if legacy_spec is not None else None\n",
    "    if expected_legacy is not None and len(lam_grouped) == expected_legacy:\n",
    "        lam = []\n",
    "        idx = 0\n",
    "        for ts, gs in legacy_spec:\n",
    "            for _ in range(ts):\n",
    "                lam.extend([lam_grouped[idx]] * gs)\n",
    "                idx += 1\n",
    "        lam.append(lam_grouped[-1])\n",
    "        if len(lam) != n_steps + 1:\n",
    "            raise ValueError(f'expanded legacy lam length {len(lam)} != n_steps+1 ({n_steps+1})')\n",
    "        return lam\n",
    "\n",
    "    raise ValueError(\n",
    "        f'grouped lam length {len(lam_grouped)} != expected_c {expected_c}'\n",
    "        + (f' and != expected_legacy {expected_legacy}' if expected_legacy is not None else '')\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_t_grid(n_steps: int, t_max: float, alpha: float = 0.1):\n",
    "    beta = math.log(1 + t_max / alpha) / n_steps\n",
    "    t = [alpha * (math.exp(beta * k) - 1.0) for k in range(n_steps)]\n",
    "    t.append(float(t_max))\n",
    "    return np.asarray(t, dtype=float)\n",
    "\n",
    "\n",
    "def curve_from_json(path: Path):\n",
    "    d = json.loads(path.read_text())\n",
    "    theta = float(d['theta'])\n",
    "    mu = float(d.get('mu', MU))\n",
    "    n_steps = int(d['n_steps'])\n",
    "    t_max = float(d['t_max'])\n",
    "    bin_size = float(d.get('bin_size', WINDOW_BP))\n",
    "\n",
    "    pattern_raw = d.get('pattern')\n",
    "    pattern_spec = parse_pattern_spec(pattern_raw)\n",
    "    lam = np.asarray(expand_lam(d['lam'], n_steps, pattern_spec, pattern_raw=pattern_raw), dtype=float)\n",
    "\n",
    "    n0 = theta / (4.0 * mu * bin_size)\n",
    "    t = compute_t_grid(n_steps, t_max)\n",
    "\n",
    "    x = t * 2.0 * GEN_YEARS * n0\n",
    "    y = lam * n0\n",
    "\n",
    "    x = np.append(x, 1e8)\n",
    "    y = np.append(y, y[-1])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def step_value(xs: np.ndarray, ys: np.ndarray, xq: float) -> float:\n",
    "    idx = np.searchsorted(xs, xq, side='right') - 1\n",
    "    idx = max(0, min(idx, len(ys) - 1))\n",
    "    return float(ys[idx])\n",
    "\n",
    "\n",
    "def rmse_log10(curve_a, curve_b, x_min=1e3, x_max=1e8, n=400):\n",
    "    xa, ya = curve_a\n",
    "    xb, yb = curve_b\n",
    "    grid = np.geomspace(x_min, x_max, n)\n",
    "    va = np.array([step_value(xa, ya, x) for x in grid])\n",
    "    vb = np.array([step_value(xb, yb, x) for x in grid])\n",
    "    m = (va > 0) & (vb > 0) & np.isfinite(va) & np.isfinite(vb)\n",
    "    if m.sum() == 0:\n",
    "        return float('nan')\n",
    "    return float(np.sqrt(np.mean((np.log10(va[m]) - np.log10(vb[m])) ** 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics = []\n",
    "\n",
    "\n",
    "def _step_outline(ax, x, y, *, color, lw=2.0, ls='-', label=None, zorder=3):\n",
    "    line = ax.step(x, y, where='post', color=color, lw=lw, ls=ls, label=label, zorder=zorder)[0]\n",
    "    line.set_path_effects([\n",
    "        pe.Stroke(linewidth=lw + 1.4, foreground='white', alpha=0.92),\n",
    "        pe.Normal(),\n",
    "    ])\n",
    "    return line\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(14.6, 11.4), dpi=160, constrained_layout=True)\n",
    "outer = fig.add_gridspec(2, 2, wspace=0.10, hspace=0.14)\n",
    "main_axes = []\n",
    "diff_axes = []\n",
    "\n",
    "for i, key in enumerate(MODEL_ORDER):\n",
    "    rr, cc = divmod(i, 2)\n",
    "    inner = outer[rr, cc].subgridspec(2, 1, height_ratios=[4.0, 1.3], hspace=0.05)\n",
    "    ax = fig.add_subplot(inner[0])\n",
    "    axd = fig.add_subplot(inner[1], sharex=ax)\n",
    "    main_axes.append(ax)\n",
    "    diff_axes.append(axd)\n",
    "\n",
    "    p = model_paths(key)\n",
    "\n",
    "    true_curve = true_curve_for_model(key)\n",
    "    psmcfa_curve = curve_from_json(p.rust_psmcfa_json)\n",
    "    mhs_curve = curve_from_json(p.rust_mhs_json)\n",
    "    vcf_curve = curve_from_json(p.rust_vcf_json)\n",
    "\n",
    "    tx, ty = true_curve\n",
    "    x1, y1 = psmcfa_curve\n",
    "    x2, y2 = mhs_curve\n",
    "    x3, y3 = vcf_curve\n",
    "\n",
    "    _step_outline(ax, tx, ty, lw=2.2, ls=(0, (5, 3)), color='dodgerblue', label='True', zorder=1)\n",
    "    _step_outline(ax, x1, y1, lw=2.0, color='tomato', label='PSMCFA input', zorder=2)\n",
    "    _step_outline(ax, x2, y2, lw=1.9, color='seagreen', label='MHS input', zorder=3)\n",
    "    _step_outline(ax, x3, y3, lw=1.9, color='mediumpurple', label='VCF input', zorder=4)\n",
    "\n",
    "    ymax = max(float(np.max(ty)), float(np.max(y1)), float(np.max(y2)), float(np.max(y3)))\n",
    "    ax.set_title(MODELS[key]['title'])\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlim(1e3, 1e8)\n",
    "    ax.set_ylim(0, ymax * 1.15)\n",
    "    ax.set_ylabel('Effective population size (Ne)')\n",
    "    ax.grid(alpha=0.25)\n",
    "    ax.tick_params(labelbottom=False)\n",
    "\n",
    "    xg = np.geomspace(1e3, 1e8, 800)\n",
    "    l1 = np.log10(np.asarray([max(step_value(x1, y1, x), 1e-12) for x in xg], dtype=float))\n",
    "    l2 = np.log10(np.asarray([max(step_value(x2, y2, x), 1e-12) for x in xg], dtype=float))\n",
    "    l3 = np.log10(np.asarray([max(step_value(x3, y3, x), 1e-12) for x in xg], dtype=float))\n",
    "    d_mhs = l2 - l1\n",
    "    d_vcf = l3 - l1\n",
    "\n",
    "    axd.axhline(0.0, color='#6B7280', lw=1.0, ls=(0, (4, 2)))\n",
    "    axd.plot(xg, d_mhs, color='seagreen', lw=1.7, label='MHS - PSMCFA')\n",
    "    axd.plot(xg, d_vcf, color='mediumpurple', lw=1.7, label='VCF - PSMCFA')\n",
    "    axd.set_xscale('log')\n",
    "    axd.set_xlim(1e3, 1e8)\n",
    "    lim = max(0.005, min(0.2, float(np.max(np.abs(np.concatenate([d_mhs, d_vcf])))) * 1.25))\n",
    "    axd.set_ylim(-lim, lim)\n",
    "    axd.set_xlabel(f'Years (g={GEN_YEARS}, mu={MU:.1e})')\n",
    "    axd.set_ylabel('Delta log10(Ne)', fontsize=9)\n",
    "    axd.grid(alpha=0.25)\n",
    "    axd.tick_params(axis='both', labelsize=8.3)\n",
    "\n",
    "    metrics.append({\n",
    "        'model': key,\n",
    "        'rmse_log10_ne_vs_true_psmcfa': rmse_log10(true_curve, psmcfa_curve),\n",
    "        'rmse_log10_ne_vs_true_mhs': rmse_log10(true_curve, mhs_curve),\n",
    "        'rmse_log10_ne_vs_true_vcf': rmse_log10(true_curve, vcf_curve),\n",
    "        'rmse_log10_ne_mhs_vs_psmcfa': rmse_log10(mhs_curve, psmcfa_curve),\n",
    "        'rmse_log10_ne_vcf_vs_psmcfa': rmse_log10(vcf_curve, psmcfa_curve),\n",
    "        'rmse_log10_ne_vcf_vs_mhs': rmse_log10(vcf_curve, mhs_curve),\n",
    "    })\n",
    "\n",
    "handles, labels = main_axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', ncol=4, frameon=False, bbox_to_anchor=(0.5, 1.02))\n",
    "h2, l2 = diff_axes[0].get_legend_handles_labels()\n",
    "diff_axes[0].legend(h2, l2, loc='lower left', fontsize=8.2, frameon=False)\n",
    "fig.suptitle('500Mb format consistency: psmcfa vs mhs vs vcf', fontsize=15.5, fontweight='bold', y=1.04)\n",
    "plt.show()\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics).sort_values('model')\n",
    "run_pivot = run_df.pivot(index='model', columns='format', values='wall_sec').reset_index()\n",
    "summary_df = metrics_df.merge(run_pivot, on='model', how='left')\n",
    "summary_df['speed_ratio_mhs_over_psmcfa'] = summary_df['mhs'] / summary_df['psmcfa']\n",
    "summary_df['speed_ratio_vcf_over_psmcfa'] = summary_df['vcf'] / summary_df['psmcfa']\n",
    "\n",
    "print('Summary metrics (lower RMSE is better)')\n",
    "display(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- This is a **format comparison** under matched simulation and inference settings.\n",
    "- `MHS`, `PSMCFA`, and `VCF` are generated from the **same simulated diploid genome** per model.\n",
    "- If runtime is too long on your machine, reduce `SIM_LENGTH_BP` (e.g., `5e7`) and rerun.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}