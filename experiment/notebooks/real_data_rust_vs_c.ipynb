{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Real Data Benchmark: Rust vs C (PSMC)\n\nThis notebook runs `psmc-rs` and original C `psmc` on four real diploid `psmcfa` samples,\nthen generates clean comparison figures (`PNG/SVG/PDF`) for manuscript use.\n\nFairness settings:\n- Same PSMC core settings for Rust and C (`-N`, `-t`, `-r`, `-p`)\n- Rust smoothing disabled (`--smooth-lambda 0`)\n- Single-thread (`--threads 1`) for Rust-vs-C runtime fairness\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from __future__ import annotations\n\nimport json\nimport math\nimport os\nimport shlex\nimport subprocess\nimport time\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FuncFormatter\n\ntry:\n    from IPython.display import display\nexcept Exception:\n    def display(x):\n        print(x)\n\n\ndef find_repo_root(start: Path) -> Path:\n    for p in [start, *start.parents]:\n        if (p / 'Cargo.toml').exists() and (p / 'src').exists():\n            return p\n    raise RuntimeError(f'Cannot locate psmc-rs root from {start}')\n\n\nROOT = find_repo_root(Path.cwd().resolve())\nRUN_DIR = ROOT / 'experiment' / 'runs' / 'real_data'\nOUT_DIR = RUN_DIR / 'outputs'\nFIG_DIR = RUN_DIR / 'figures'\nTAB_DIR = RUN_DIR / 'tables'\nLOG_DIR = RUN_DIR / 'logs'\n\nfor d in (RUN_DIR, OUT_DIR, FIG_DIR, TAB_DIR, LOG_DIR):\n    d.mkdir(parents=True, exist_ok=True)\n\nPSMC_RS_BIN = Path(os.environ.get('PSMC_RS_BIN', str(ROOT / 'target' / 'release' / 'psmc-rs')))\nC_PSMC_BIN = Path(os.environ.get('C_PSMC_BIN', str(ROOT.parent / 'psmc-master' / 'psmc')))\n\nplt.rcParams.update({\n    'figure.facecolor': 'white',\n    'savefig.facecolor': 'white',\n    'axes.facecolor': 'white',\n    'axes.edgecolor': '#B7C3D0',\n    'axes.linewidth': 0.9,\n    'axes.titleweight': 'semibold',\n    'axes.labelcolor': '#334155',\n    'xtick.color': '#475569',\n    'ytick.color': '#475569',\n    'grid.color': '#E6ECF3',\n    'grid.linewidth': 0.7,\n    'grid.alpha': 0.9,\n    'font.family': 'DejaVu Sans',\n    'font.size': 10.5,\n    'legend.frameon': False,\n    'pdf.fonttype': 42,\n    'ps.fonttype': 42,\n    'svg.fonttype': 'none',\n})\n\nCOL = {\n    'rust': '#E15759',\n    'c': '#59A14F',\n    'delta': '#2563EB',\n    'axis': '#334155',\n}\n\nprint('ROOT:', ROOT)\nprint('RUN_DIR:', RUN_DIR)\nprint('PSMC_RS_BIN:', PSMC_RS_BIN)\nprint('C_PSMC_BIN:', C_PSMC_BIN)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "@dataclass\nclass SampleCfg:\n    sid: str\n    file: Path\n    species: str\n    group: str\n    mu: float\n    gen_years: float\n\n\nSAMPLES: List[SampleCfg] = [\n    SampleCfg(\n        sid='HLemySub1',\n        file=ROOT / 'experiment' / 'real_data' / 'HLemySub1_diploid.psmcfa',\n        species='HLemySub1 (likely Emydura subglobosa)',\n        group='Turtle',\n        mu=7.9e-9,\n        gen_years=15.0,\n    ),\n    SampleCfg(\n        sid='Papuan_highlands',\n        file=ROOT / 'experiment' / 'real_data' / 'Papuan_highlands_diploid.psmcfa',\n        species='Homo sapiens (Papuan Highlands)',\n        group='Human',\n        mu=1.25e-8,\n        gen_years=25.0,\n    ),\n    SampleCfg(\n        sid='PD_0030_A_preussi',\n        file=ROOT / 'experiment' / 'real_data' / 'PD_0030_Allochrocebus_preussi.psmcfa',\n        species='Allochrocebus preussi',\n        group='Primate',\n        mu=4.91e-9,\n        gen_years=10.0,\n    ),\n    SampleCfg(\n        sid='PD_0032_C_ascanius_schmidti',\n        file=ROOT / 'experiment' / 'real_data' / 'PD_0032_Cercopithecus_ascanius_schmidti.psmcfa',\n        species='Cercopithecus ascanius schmidti',\n        group='Primate',\n        mu=4.82e-9,\n        gen_years=12.0,\n    ),\n]\n\n# Matched settings for Rust vs C\nN_ITER = int(os.environ.get('N_ITER', '20'))\nT_MAX = float(os.environ.get('T_MAX', '15'))\nN_STEPS = int(os.environ.get('N_STEPS', '64'))\nPATTERN = os.environ.get('PATTERN', '4+25*2+4+6')\nRHO_T_RATIO = int(os.environ.get('RHO_T_RATIO', '5'))\nBATCH_SIZE = int(os.environ.get('BATCH_SIZE', '300000'))\nTHREADS = int(os.environ.get('THREADS', '1'))\nSMOOTH_LAMBDA = float(os.environ.get('SMOOTH_LAMBDA', '0'))\nBIN_SIZE = int(os.environ.get('BIN_SIZE', '100'))\nFORCE_RUN = os.environ.get('FORCE_RUN', '0') == '1'\n\nmeta = pd.DataFrame([\n    {\n        'sample_id': s.sid,\n        'species': s.species,\n        'group': s.group,\n        'mu': s.mu,\n        'gen_years': s.gen_years,\n        'input_file': str(s.file),\n        'exists': s.file.exists(),\n    }\n    for s in SAMPLES\n])\ndisplay(meta)\n\nmissing = [str(s.file) for s in SAMPLES if not s.file.exists()]\nif missing:\n    raise FileNotFoundError('Missing input files:\\n' + '\\n'.join(missing))\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def save_figure_multi(fig, stem: str):\n    paths = []\n    for ext in ('png', 'svg', 'pdf'):\n        p = FIG_DIR / f'{stem}.{ext}'\n        fig.savefig(p, dpi=320 if ext == 'png' else None, bbox_inches='tight')\n        paths.append(p)\n    print('saved figure:', ', '.join(str(p) for p in paths))\n\n\ndef save_table_multi(df: pd.DataFrame, stem: str):\n    csv_p = TAB_DIR / f'{stem}.csv'\n    tsv_p = TAB_DIR / f'{stem}.tsv'\n    md_p = TAB_DIR / f'{stem}.md'\n    df.to_csv(csv_p, index=False)\n    df.to_csv(tsv_p, index=False, sep='\t')\n    md_p.write_text(df.to_markdown(index=False) + '\\n', encoding='utf-8')\n    print('saved table:', csv_p, tsv_p, md_p)\n\n\ndef run_cmd(cmd: List[str], cwd: Optional[Path] = None, check: bool = True):\n    t0 = time.perf_counter()\n    proc = subprocess.run(\n        cmd,\n        cwd=str(cwd) if cwd is not None else None,\n        capture_output=True,\n        text=True,\n    )\n    dt = time.perf_counter() - t0\n    rec = {\n        'cmd': ' '.join(shlex.quote(x) for x in cmd),\n        'returncode': proc.returncode,\n        'wall_sec': dt,\n        'stdout': proc.stdout,\n        'stderr': proc.stderr,\n    }\n    with (LOG_DIR / 'commands.jsonl').open('a', encoding='utf-8') as f:\n        f.write(json.dumps(rec, ensure_ascii=False) + '\\n')\n\n    if check and proc.returncode != 0:\n        print(rec['cmd'])\n        print('--- stdout ---')\n        print(proc.stdout)\n        print('--- stderr ---')\n        print(proc.stderr)\n        raise RuntimeError(f'command failed: rc={proc.returncode}')\n    return rec\n\n\ndef rust_out_json(s: SampleCfg) -> Path:\n    return OUT_DIR / f'{s.sid}.rust.json'\n\n\ndef c_out_psmc(s: SampleCfg) -> Path:\n    return OUT_DIR / f'{s.sid}.c.psmc'\n\n\ndef run_rust(s: SampleCfg):\n    out_json = rust_out_json(s)\n    cmd = [\n        str(PSMC_RS_BIN),\n        str(s.file),\n        str(out_json),\n        str(N_ITER),\n        '--t-max', str(T_MAX),\n        '--n-steps', str(N_STEPS),\n        '--pattern', PATTERN,\n        '--mu', str(s.mu),\n        '--smooth-lambda', str(SMOOTH_LAMBDA),\n        '--batch-size', str(BATCH_SIZE),\n        '--threads', str(THREADS),\n        '--no-progress',\n    ]\n    rec = run_cmd(cmd, cwd=ROOT)\n    return out_json, rec\n\n\ndef run_c(s: SampleCfg):\n    out_psmc = c_out_psmc(s)\n    cmd = [\n        str(C_PSMC_BIN),\n        f'-N{N_ITER}',\n        f'-t{T_MAX}',\n        f'-r{RHO_T_RATIO}',\n        '-p', PATTERN,\n        '-o', str(out_psmc),\n        str(s.file),\n    ]\n    rec = run_cmd(cmd, cwd=ROOT)\n    return out_psmc, rec\n\n\nif not PSMC_RS_BIN.exists():\n    raise FileNotFoundError(f'psmc-rs binary not found: {PSMC_RS_BIN}')\nif not C_PSMC_BIN.exists():\n    raise FileNotFoundError(f'C psmc binary not found: {C_PSMC_BIN}')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def parse_pattern_spec(pattern):\n    if pattern is None:\n        return None\n    out = []\n    for part in str(pattern).split('+'):\n        part = part.strip()\n        if not part:\n            continue\n        if '*' in part:\n            a, b = part.split('*', 1)\n            nr = int(a.strip())\n            gl = int(b.strip())\n        else:\n            nr = 1\n            gl = int(part)\n        out.append((nr, gl))\n    return out if out else None\n\n\ndef parse_pattern_spec_legacy(pattern):\n    if pattern is None:\n        return None\n    out = []\n    for part in str(pattern).split('+'):\n        part = part.strip()\n        if not part:\n            continue\n        if '*' in part:\n            a, b = part.split('*', 1)\n            ts = int(a.strip())\n            gs = int(b.strip())\n        else:\n            ts = int(part)\n            gs = 1\n        out.append((ts, gs))\n    return out if out else None\n\n\ndef expand_lam(lam_grouped, n_steps, pattern_spec, pattern_raw=None):\n    lam_grouped = list(map(float, lam_grouped))\n    if pattern_spec is None:\n        if len(lam_grouped) != n_steps + 1:\n            raise ValueError(f'lam length {len(lam_grouped)} != n_steps+1 ({n_steps+1})')\n        return lam_grouped\n\n    expected_c = sum(nr for nr, _ in pattern_spec)\n    if len(lam_grouped) == expected_c:\n        lam = []\n        idx = 0\n        for nr, gl in pattern_spec:\n            for _ in range(nr):\n                lam.extend([lam_grouped[idx]] * gl)\n                idx += 1\n        if len(lam) != n_steps + 1:\n            raise ValueError(f'expanded lam length {len(lam)} != n_steps+1 ({n_steps+1})')\n        return lam\n\n    legacy = parse_pattern_spec_legacy(pattern_raw)\n    expected_legacy = sum(ts for ts, _ in legacy) + 1 if legacy is not None else None\n    if expected_legacy is not None and len(lam_grouped) == expected_legacy:\n        lam = []\n        idx = 0\n        for ts, gs in legacy:\n            for _ in range(ts):\n                lam.extend([lam_grouped[idx]] * gs)\n                idx += 1\n        lam.append(lam_grouped[-1])\n        if len(lam) != n_steps + 1:\n            raise ValueError(f'expanded legacy lam length {len(lam)} != n_steps+1 ({n_steps+1})')\n        return lam\n\n    raise ValueError('grouped lam length mismatch with pattern')\n\n\ndef compute_t_grid(n_steps: int, t_max: float, alpha: float = 0.1):\n    beta = math.log(1 + t_max / alpha) / n_steps\n    t = [alpha * (math.exp(beta * k) - 1.0) for k in range(n_steps)]\n    t.append(float(t_max))\n    return np.asarray(t, dtype=float)\n\n\ndef curve_from_json(path: Path, mu: float, gen_years: float, bin_size: int = BIN_SIZE):\n    params = json.loads(path.read_text())\n    theta = float(params['theta'])\n    n_steps = int(params['n_steps'])\n    t_max = float(params['t_max'])\n    pattern_raw = params.get('pattern')\n    pattern_spec = parse_pattern_spec(pattern_raw)\n    lam = np.asarray(expand_lam(params['lam'], n_steps, pattern_spec, pattern_raw), dtype=float)\n\n    t = compute_t_grid(n_steps, t_max)\n    n0 = theta / (4.0 * float(mu) * float(bin_size))\n    x = t * 2.0 * float(gen_years) * n0\n    y = lam * n0\n    x = np.append(x, 1e8)\n    y = np.append(y, y[-1])\n    return np.asarray(x, dtype=float), np.asarray(y, dtype=float)\n\n\ndef load_c_curve(psmc_path: Path, mu: float, gen_years: float, bin_size: int = BIN_SIZE):\n    lines = psmc_path.read_text().splitlines()\n    blocks = []\n    cur = None\n    for ln in lines:\n        if ln.startswith('RD\t'):\n            if cur is not None:\n                blocks.append(cur)\n            cur = {'tr': None, 'pa': None, 'rs': []}\n        elif cur is not None and ln.startswith('TR\t'):\n            _, th, rh = ln.split('\t')[:3]\n            cur['tr'] = (float(th), float(rh))\n        elif cur is not None and ln.startswith('PA\t'):\n            cur['pa'] = ln\n        elif cur is not None and ln.startswith('RS\t'):\n            t = ln.split('\t')\n            cur['rs'].append((int(t[1]), float(t[2]), float(t[3])))\n    if cur is not None:\n        blocks.append(cur)\n\n    best = None\n    for b in blocks[::-1]:\n        if b['pa'] and b['tr'] is not None and b['rs']:\n            best = b\n            break\n    if best is None:\n        raise ValueError(f'cannot parse valid block in {psmc_path}')\n\n    theta = best['tr'][0]\n    n0 = theta / (4.0 * float(mu) * float(bin_size))\n    xs = []\n    ys = []\n    for _, tk, lk in best['rs']:\n        xs.append(2.0 * n0 * tk * float(gen_years))\n        ys.append(n0 * lk)\n    xs.append(1e8)\n    ys.append(ys[-1])\n    return np.asarray(xs, dtype=float), np.asarray(ys, dtype=float)\n\n\ndef step_value(xs: np.ndarray, ys: np.ndarray, xq: float) -> float:\n    idx = int(np.searchsorted(xs, xq, side='right') - 1)\n    idx = max(0, min(idx, len(ys) - 1))\n    return float(ys[idx])\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "records = []\ncurves: Dict[str, Dict[str, np.ndarray]] = {}\n\nfor s in SAMPLES:\n    print(f'\\n[run] {s.sid}')\n\n    r_json = rust_out_json(s)\n    c_psmc = c_out_psmc(s)\n\n    rust_rec = {'wall_sec': np.nan}\n    c_rec = {'wall_sec': np.nan}\n\n    if FORCE_RUN or not r_json.exists():\n        _, rust_rec = run_rust(s)\n    if FORCE_RUN or not c_psmc.exists():\n        _, c_rec = run_c(s)\n\n    xr, yr = curve_from_json(r_json, mu=s.mu, gen_years=s.gen_years)\n    xc, yc = load_c_curve(c_psmc, mu=s.mu, gen_years=s.gen_years)\n\n    curves[s.sid] = {\n        'x_rust': xr,\n        'y_rust': yr,\n        'x_c': xc,\n        'y_c': yc,\n    }\n\n    xg = np.geomspace(max(1e3, min(xr.min(), xc.min())), min(1e8, max(xr.max(), xc.max())), 600)\n    lr = np.log10(np.asarray([max(step_value(xr, yr, x), 1e-12) for x in xg]))\n    lc = np.log10(np.asarray([max(step_value(xc, yc, x), 1e-12) for x in xg]))\n    rmse = float(np.sqrt(np.mean((lr - lc) ** 2)))\n\n    records.append({\n        'sample_id': s.sid,\n        'species': s.species,\n        'group': s.group,\n        'mu': s.mu,\n        'gen_years': s.gen_years,\n        'rust_json': str(r_json),\n        'c_psmc': str(c_psmc),\n        'rmse_log10_ne_rust_vs_c': rmse,\n        'rust_wall_sec': rust_rec['wall_sec'],\n        'c_wall_sec': c_rec['wall_sec'],\n    })\n\nsummary = pd.DataFrame(records).sort_values('sample_id').reset_index(drop=True)\nsave_table_multi(summary, 'real_data_rust_vs_c_summary')\ndisplay(summary)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def style_axis(ax, yfmt=True):\n    ax.set_xscale('log')\n    ax.grid(True, which='major')\n    ax.grid(False, which='minor')\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    if yfmt:\n        ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: f'{y:,.0f}'))\n\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 9.2), dpi=250, constrained_layout=True)\naxes = axes.flatten()\n\nfor i, s in enumerate(SAMPLES):\n    ax = axes[i]\n    c = curves[s.sid]\n\n    ax.step(c['x_c'], c['y_c'], where='post', color=COL['c'], lw=2.0, label='C', zorder=2)\n    ax.step(c['x_rust'], c['y_rust'], where='post', color=COL['rust'], lw=2.0, label='Rust', zorder=3)\n\n    style_axis(ax)\n    ax.set_xlim(1e3, 1e8)\n    ymax = max(float(np.max(c['y_c'])), float(np.max(c['y_rust'])))\n    ax.set_ylim(0, ymax * 1.12)\n\n    ax.set_title(s.species, fontsize=12.7, pad=7)\n    if i % 2 == 0:\n        ax.set_ylabel('Effective population size (Ne)')\n    if i >= 2:\n        ax.set_xlabel('Years')\n\n    rmse = summary.loc[summary.sample_id == s.sid, 'rmse_log10_ne_rust_vs_c'].iloc[0]\n    ax.text(\n        0.985, 0.965,\n        f'RMSE(log10 Ne)={rmse:.3f}\\nμ={s.mu:.2e}, g={s.gen_years:.0f}',\n        transform=ax.transAxes,\n        ha='right', va='top', fontsize=8.4, color='#425466',\n        bbox={'boxstyle': 'round,pad=0.22', 'fc': 'white', 'ec': '#D5DFEA', 'lw': 0.75, 'alpha': 0.95},\n    )\n\n    ax.text(0.012, 0.985, chr(ord('A') + i), transform=ax.transAxes,\n            ha='left', va='top', fontsize=12, color='#44576B', fontweight='semibold')\n\nh, l = axes[0].get_legend_handles_labels()\nfig.legend(h, l, loc='upper center', ncol=2, bbox_to_anchor=(0.5, 1.01))\nfig.suptitle('Real Data: PSMC-RS vs Original C PSMC', fontsize=17, y=1.04, fontweight='semibold')\n\nsave_figure_multi(fig, 'real_data_rust_vs_c')\nplt.show()\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(2, 2, figsize=(14, 7.8), dpi=250, constrained_layout=True)\naxes = axes.flatten()\n\nfor i, s in enumerate(SAMPLES):\n    ax = axes[i]\n    c = curves[s.sid]\n\n    x_min = max(1e3, min(float(c['x_rust'].min()), float(c['x_c'].min())))\n    x_max = min(1e8, max(float(c['x_rust'].max()), float(c['x_c'].max())))\n    xg = np.geomspace(x_min, x_max, 650)\n\n    lr = np.log10(np.asarray([max(step_value(c['x_rust'], c['y_rust'], x), 1e-12) for x in xg]))\n    lc = np.log10(np.asarray([max(step_value(c['x_c'], c['y_c'], x), 1e-12) for x in xg]))\n    d = lr - lc\n\n    ax.axhline(0.0, color='#64748B', lw=1.0, ls=(0, (4, 2)))\n    ax.plot(xg, d, color=COL['delta'], lw=1.8)\n    ax.fill_between(xg, 0, d, where=d>=0, color=COL['delta'], alpha=0.10, linewidth=0)\n    ax.fill_between(xg, 0, d, where=d<0, color=COL['delta'], alpha=0.08, linewidth=0)\n\n    style_axis(ax, yfmt=False)\n    ax.set_xlim(1e3, 1e8)\n    lim = max(0.04, min(1.0, float(np.max(np.abs(d))) * 1.22))\n    ax.set_ylim(-lim, lim)\n    ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: f'{y:+.2f}'))\n\n    ax.set_title(s.species, fontsize=12.2, pad=6)\n    if i % 2 == 0:\n        ax.set_ylabel('Δ log10(Ne)  (Rust - C)')\n    if i >= 2:\n        ax.set_xlabel('Years')\n\n    ax.text(0.012, 0.985, chr(ord('A') + i), transform=ax.transAxes,\n            ha='left', va='top', fontsize=12, color='#44576B', fontweight='semibold')\n\nfig.suptitle('Real Data: Difference Curve (Rust - C)', fontsize=16, y=1.03, fontweight='semibold')\nsave_figure_multi(fig, 'real_data_rust_minus_c_delta')\nplt.show()\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print('Notebook outputs:')\nprint(' - Figures:', FIG_DIR)\nprint(' - Tables :', TAB_DIR)\nprint(' - Logs   :', LOG_DIR / 'commands.jsonl')\nprint('\\nIf you want to re-run all inference from scratch in this notebook:')\nprint('  set FORCE_RUN=1 in environment before launching Jupyter, or edit FORCE_RUN=True in config cell.')\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}