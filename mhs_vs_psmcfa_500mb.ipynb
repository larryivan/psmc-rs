{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PSMC-RS: MHS vs PSMCFA (500Mb, 4 demographic models)\n",
        "\n",
        "This notebook:\n",
        "1. Simulates **the same diploid genome** with `msprime` for 4 models (`constant`, `bottleneck`, `expansion`, `zigzag`).\n",
        "2. Serializes each simulation into **both** input formats:\n",
        "   - `psmcfa`\n",
        "   - official `multihetsep/mhs` (`chrom pos nr_called alleles`)\n",
        "3. Runs `psmc-rs` on both formats with matched inference settings.\n",
        "4. Plots and quantifies differences (`MHS` vs `PSMCFA`) and recovery vs true curve.\n",
        "\n",
        "> Default length is **500,000,000 bp** per model. You can override via `SIM_LENGTH_BP` env var before launching Jupyter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import platform\n",
        "import shlex\n",
        "import subprocess\n",
        "import sys\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import msprime\n",
        "\n",
        "ROOT = Path.cwd().resolve()\n",
        "assert (ROOT / 'Cargo.toml').exists(), f'Please run this notebook in psmc-rs root. current={ROOT}'\n",
        "\n",
        "EXP_DIR = ROOT / 'experiments' / 'mhs_vs_psmcfa_500mb'\n",
        "INPUT_DIR = EXP_DIR / 'inputs'\n",
        "OUTPUT_DIR = EXP_DIR / 'outputs'\n",
        "for d in (EXP_DIR, INPUT_DIR, OUTPUT_DIR):\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "PSMC_RS_BIN = Path(os.environ.get('PSMC_RS_BIN', str(ROOT / 'target' / 'release' / 'psmc-rs')))\n",
        "\n",
        "# Core run config\n",
        "SIM_LENGTH_BP = int(os.environ.get('SIM_LENGTH_BP', '500000000'))\n",
        "WINDOW_BP = int(os.environ.get('WINDOW_BP', '100'))\n",
        "MU = float(os.environ.get('MU', '2.5e-8'))\n",
        "RECOMB = float(os.environ.get('RECOMB', '1.25e-8'))\n",
        "GEN_YEARS = float(os.environ.get('GEN_YEARS', '25'))\n",
        "\n",
        "N_ITER = int(os.environ.get('N_ITER', '20'))\n",
        "T_MAX = float(os.environ.get('T_MAX', '15'))\n",
        "N_STEPS = int(os.environ.get('N_STEPS', '64'))\n",
        "PATTERN = os.environ.get('PATTERN', '4+25*2+4+6')\n",
        "BATCH_SIZE = int(os.environ.get('BATCH_SIZE', '300000'))\n",
        "THREADS = int(os.environ.get('THREADS', '1'))\n",
        "SMOOTH_LAMBDA = float(os.environ.get('SMOOTH_LAMBDA', '1e-3'))\n",
        "FORCE_SIM = os.environ.get('FORCE_SIM', '1').strip() != '0'\n",
        "\n",
        "print(f'ROOT={ROOT}')\n",
        "print(f'Python={sys.executable}')\n",
        "print(f'Platform={platform.platform()}')\n",
        "print(f'msprime={msprime.__version__}')\n",
        "print(f'PSMC_RS_BIN={PSMC_RS_BIN}')\n",
        "print(f'SIM_LENGTH_BP={SIM_LENGTH_BP:,}, WINDOW_BP={WINDOW_BP}, symbols={math.ceil(SIM_LENGTH_BP / WINDOW_BP):,}')\n",
        "print(f'MU={MU:.3e}, RECOMB={RECOMB:.3e}, GEN_YEARS={GEN_YEARS}')\n",
        "print(f'N_ITER={N_ITER}, T_MAX={T_MAX}, N_STEPS={N_STEPS}, PATTERN={PATTERN}')\n",
        "print(f'BATCH_SIZE={BATCH_SIZE}, THREADS={THREADS}, SMOOTH_LAMBDA={SMOOTH_LAMBDA}')\n",
        "print(f'FORCE_SIM={FORCE_SIM} (set FORCE_SIM=0 to reuse existing inputs)')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_cmd(cmd: List[str], cwd: Optional[Path] = None, check: bool = True):\n",
        "    start = time.perf_counter()\n",
        "    proc = subprocess.run(\n",
        "        cmd,\n",
        "        cwd=str(cwd) if cwd is not None else None,\n",
        "        text=True,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "    )\n",
        "    dt = time.perf_counter() - start\n",
        "    rec = {\n",
        "        'cmd': ' '.join(shlex.quote(x) for x in cmd),\n",
        "        'returncode': proc.returncode,\n",
        "        'stdout': proc.stdout,\n",
        "        'stderr': proc.stderr,\n",
        "        'wall_sec': dt,\n",
        "    }\n",
        "    if check and proc.returncode != 0:\n",
        "        print(rec['cmd'])\n",
        "        print('--- stdout ---')\n",
        "        print(proc.stdout)\n",
        "        print('--- stderr ---')\n",
        "        print(proc.stderr)\n",
        "        raise RuntimeError(f'command failed: rc={proc.returncode}')\n",
        "    return rec\n",
        "\n",
        "\n",
        "def ensure_psmc_rs_release_binary() -> Path:\n",
        "    if PSMC_RS_BIN.exists():\n",
        "        return PSMC_RS_BIN\n",
        "    print('[build] cargo build --release')\n",
        "    run_cmd(['cargo', 'build', '--release'], cwd=ROOT)\n",
        "    if not PSMC_RS_BIN.exists():\n",
        "        raise FileNotFoundError(f'psmc-rs binary not found after build: {PSMC_RS_BIN}')\n",
        "    return PSMC_RS_BIN\n",
        "\n",
        "\n",
        "ensure_psmc_rs_release_binary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def coalescent_events_to_generations(n0: float, events_4n0: List[Tuple[float, float]]) -> List[Tuple[float, float]]:\n",
        "    return [(t4 * 4.0 * n0, ratio * n0) for (t4, ratio) in events_4n0]\n",
        "\n",
        "\n",
        "MODELS: Dict[str, Dict] = {\n",
        "    'constant': {\n",
        "        'title': 'Constant',\n",
        "        'n0': 10_000.0,\n",
        "        'events_gen': [],\n",
        "        'seed': 42,\n",
        "    },\n",
        "    'bottleneck': {\n",
        "        'title': 'Bottleneck',\n",
        "        'n0': 20_000.0,\n",
        "        'events_gen': coalescent_events_to_generations(20_000.0, [\n",
        "            (0.01, 0.05),\n",
        "            (0.015, 0.5),\n",
        "            (0.05, 0.25),\n",
        "            (0.5, 0.5),\n",
        "        ]),\n",
        "        'seed': 43,\n",
        "    },\n",
        "    'expansion': {\n",
        "        'title': 'Expansion',\n",
        "        'n0': 10_000.0,\n",
        "        'events_gen': coalescent_events_to_generations(10_000.0, [\n",
        "            (0.01, 0.1),\n",
        "            (0.06, 1.0),\n",
        "            (0.2, 0.5),\n",
        "            (1.0, 1.0),\n",
        "            (2.0, 2.0),\n",
        "        ]),\n",
        "        'seed': 44,\n",
        "    },\n",
        "    'zigzag': {\n",
        "        'title': 'Zigzag',\n",
        "        'n0': 1_000.0,\n",
        "        'events_gen': coalescent_events_to_generations(1_000.0, [\n",
        "            (0.1, 5.0),\n",
        "            (0.6, 20.0),\n",
        "            (2.0, 5.0),\n",
        "            (10.0, 10.0),\n",
        "            (20.0, 5.0),\n",
        "        ]),\n",
        "        'seed': 45,\n",
        "    },\n",
        "}\n",
        "MODEL_ORDER = ['constant', 'bottleneck', 'expansion', 'zigzag']\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ModelPaths:\n",
        "    psmcfa: Path\n",
        "    mhs: Path\n",
        "    rust_psmcfa_json: Path\n",
        "    rust_mhs_json: Path\n",
        "\n",
        "\n",
        "def model_paths(key: str) -> ModelPaths:\n",
        "    return ModelPaths(\n",
        "        psmcfa=INPUT_DIR / f'{key}.psmcfa',\n",
        "        mhs=INPUT_DIR / f'{key}.multihetsep',\n",
        "        rust_psmcfa_json=OUTPUT_DIR / f'{key}.psmcfa.rust.json',\n",
        "        rust_mhs_json=OUTPUT_DIR / f'{key}.mhs.rust.json',\n",
        "    )\n",
        "\n",
        "\n",
        "def true_curve_for_model(key: str):\n",
        "    spec = MODELS[key]\n",
        "    xs = [1e3]\n",
        "    ys = [spec['n0']]\n",
        "    for t_gen, ne in sorted(spec['events_gen'], key=lambda x: x[0]):\n",
        "        xs.append(max(1e3, t_gen * GEN_YEARS))\n",
        "        ys.append(ne)\n",
        "    xs.append(1e8)\n",
        "    ys.append(ys[-1])\n",
        "    return np.array(xs, dtype=float), np.array(ys, dtype=float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_demography(n0: float, events_gen: List[Tuple[float, float]]) -> msprime.Demography:\n",
        "    dem = msprime.Demography()\n",
        "    dem.add_population(name='pop0', initial_size=float(n0))\n",
        "    for t, ne in sorted(events_gen, key=lambda x: x[0]):\n",
        "        dem.add_population_parameters_change(time=float(t), population='pop0', initial_size=float(ne))\n",
        "    return dem\n",
        "\n",
        "\n",
        "def write_psmcfa(path: Path, seq: str, header: str = 'chr1'):\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with path.open('w', encoding='utf-8') as f:\n",
        "        f.write(f'> {header}\\n')\n",
        "        wrap = 60\n",
        "        for i in range(0, len(seq), wrap):\n",
        "            f.write(seq[i:i+wrap] + '\\n')\n",
        "\n",
        "\n",
        "def simulate_model_to_both_formats(key: str, force: bool = False):\n",
        "    spec = MODELS[key]\n",
        "    p = model_paths(key)\n",
        "    if (not force) and p.psmcfa.exists() and p.mhs.exists():\n",
        "        return {\n",
        "            'model': key,\n",
        "            'sim_skipped': True,\n",
        "            'psmcfa': str(p.psmcfa),\n",
        "            'mhs': str(p.mhs),\n",
        "        }\n",
        "\n",
        "    dem = build_demography(spec['n0'], spec['events_gen'])\n",
        "    ts = msprime.sim_ancestry(\n",
        "        samples={'pop0': 1},\n",
        "        ploidy=2,\n",
        "        demography=dem,\n",
        "        sequence_length=float(SIM_LENGTH_BP),\n",
        "        recombination_rate=float(RECOMB),\n",
        "        random_seed=int(spec['seed']),\n",
        "    )\n",
        "    mts = msprime.sim_mutations(\n",
        "        ts,\n",
        "        rate=float(MU),\n",
        "        random_seed=int(spec['seed']) + 1,\n",
        "    )\n",
        "\n",
        "    n_bins = math.ceil(SIM_LENGTH_BP / WINDOW_BP)\n",
        "    has_het = np.zeros(n_bins, dtype=bool)\n",
        "\n",
        "    mhs_rows = []\n",
        "    prev_emit_pos = 0\n",
        "    het_sites = 0\n",
        "    all_sites = 0\n",
        "\n",
        "    for var in mts.variants():\n",
        "        pos = int(var.site.position) + 1  # 1-based\n",
        "        if pos < 1 or pos > SIM_LENGTH_BP:\n",
        "            continue\n",
        "        all_sites += 1\n",
        "\n",
        "        g0 = int(var.genotypes[0])\n",
        "        g1 = int(var.genotypes[1])\n",
        "        a0 = var.alleles[g0]\n",
        "        a1 = var.alleles[g1]\n",
        "\n",
        "        if a0 != a1:\n",
        "            het_sites += 1\n",
        "            idx = (pos - 1) // WINDOW_BP\n",
        "            has_het[idx] = True\n",
        "\n",
        "            nr_called = pos - prev_emit_pos\n",
        "            if nr_called <= 0:\n",
        "                continue\n",
        "            mhs_rows.append((pos, nr_called, f'{a0}{a1}'))\n",
        "            prev_emit_pos = pos\n",
        "\n",
        "    seq = ''.join('K' if x else 'T' for x in has_het)\n",
        "    write_psmcfa(p.psmcfa, seq, header='chr1')\n",
        "\n",
        "    p.mhs.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with p.mhs.open('w', encoding='utf-8') as f:\n",
        "        for pos, nr_called, alleles in mhs_rows:\n",
        "            f.write(f'chr1\\t{pos}\\t{nr_called}\\t{alleles}\\n')\n",
        "\n",
        "    return {\n",
        "        'model': key,\n",
        "        'sim_skipped': False,\n",
        "        'psmcfa': str(p.psmcfa),\n",
        "        'mhs': str(p.mhs),\n",
        "        'all_sites': all_sites,\n",
        "        'het_sites': het_sites,\n",
        "        'mhs_rows': len(mhs_rows),\n",
        "        'psmcfa_symbols': len(seq),\n",
        "        'psmcfa_mb': p.psmcfa.stat().st_size / 1e6,\n",
        "        'mhs_mb': p.mhs.stat().st_size / 1e6,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sim_rows = []\n",
        "for key in MODEL_ORDER:\n",
        "    print(f'[simulate] {key} (length={SIM_LENGTH_BP:,} bp)')\n",
        "    sim_rows.append(simulate_model_to_both_formats(key, force=FORCE_SIM))\n",
        "\n",
        "sim_df = pd.DataFrame(sim_rows)\n",
        "display(sim_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_psmc_rs(input_path: Path, input_format: str, output_json: Path):\n",
        "    cmd = [\n",
        "        str(PSMC_RS_BIN),\n",
        "        str(input_path),\n",
        "        str(output_json),\n",
        "        str(N_ITER),\n",
        "        '--input-format', input_format,\n",
        "        '--t-max', str(T_MAX),\n",
        "        '--n-steps', str(N_STEPS),\n",
        "        '--pattern', PATTERN,\n",
        "        '--mu', str(MU),\n",
        "        '--smooth-lambda', str(SMOOTH_LAMBDA),\n",
        "        '--batch-size', str(BATCH_SIZE),\n",
        "        '--threads', str(THREADS),\n",
        "        '--no-progress',\n",
        "    ]\n",
        "    if input_format == 'mhs':\n",
        "        cmd += ['--mhs-bin-size', str(WINDOW_BP)]\n",
        "    return run_cmd(cmd, cwd=ROOT)\n",
        "\n",
        "run_rows = []\n",
        "for key in MODEL_ORDER:\n",
        "    p = model_paths(key)\n",
        "\n",
        "    print(f'[run] {key} / psmcfa')\n",
        "    r1 = run_psmc_rs(p.psmcfa, 'psmcfa', p.rust_psmcfa_json)\n",
        "    run_rows.append({\n",
        "        'model': key,\n",
        "        'format': 'psmcfa',\n",
        "        'wall_sec': r1['wall_sec'],\n",
        "        'output_json': str(p.rust_psmcfa_json),\n",
        "    })\n",
        "\n",
        "    print(f'[run] {key} / mhs')\n",
        "    r2 = run_psmc_rs(p.mhs, 'mhs', p.rust_mhs_json)\n",
        "    run_rows.append({\n",
        "        'model': key,\n",
        "        'format': 'mhs',\n",
        "        'wall_sec': r2['wall_sec'],\n",
        "        'output_json': str(p.rust_mhs_json),\n",
        "    })\n",
        "\n",
        "run_df = pd.DataFrame(run_rows)\n",
        "display(run_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_pattern_spec(pattern):\n",
        "    if pattern is None:\n",
        "        return None\n",
        "    out = []\n",
        "    for part in str(pattern).split('+'):\n",
        "        part = part.strip()\n",
        "        if not part:\n",
        "            continue\n",
        "        if '*' in part:\n",
        "            a, b = part.split('*', 1)\n",
        "            nr = int(a.strip())\n",
        "            gl = int(b.strip())\n",
        "        else:\n",
        "            nr = 1\n",
        "            gl = int(part)\n",
        "        if nr <= 0 or gl <= 0:\n",
        "            raise ValueError(f'invalid pattern token: {part}')\n",
        "        out.append((nr, gl))\n",
        "    return out if out else None\n",
        "\n",
        "\n",
        "def parse_pattern_spec_legacy(pattern):\n",
        "    if pattern is None:\n",
        "        return None\n",
        "    out = []\n",
        "    for part in str(pattern).split('+'):\n",
        "        part = part.strip()\n",
        "        if not part:\n",
        "            continue\n",
        "        if '*' in part:\n",
        "            a, b = part.split('*', 1)\n",
        "            ts = int(a.strip())\n",
        "            gs = int(b.strip())\n",
        "        else:\n",
        "            ts = int(part)\n",
        "            gs = 1\n",
        "        if ts <= 0 or gs <= 0:\n",
        "            raise ValueError(f'invalid legacy token: {part}')\n",
        "        out.append((ts, gs))\n",
        "    return out if out else None\n",
        "\n",
        "\n",
        "def expand_lam(lam_grouped, n_steps, pattern_spec, pattern_raw=None):\n",
        "    lam_grouped = list(map(float, lam_grouped))\n",
        "    if pattern_spec is None:\n",
        "        if len(lam_grouped) != n_steps + 1:\n",
        "            raise ValueError(f'lam length {len(lam_grouped)} != n_steps+1 ({n_steps+1})')\n",
        "        return lam_grouped\n",
        "\n",
        "    expected_c = sum(nr for nr, _ in pattern_spec)\n",
        "    if len(lam_grouped) == expected_c:\n",
        "        lam = []\n",
        "        idx = 0\n",
        "        for nr, gl in pattern_spec:\n",
        "            for _ in range(nr):\n",
        "                lam.extend([lam_grouped[idx]] * gl)\n",
        "                idx += 1\n",
        "        if len(lam) != n_steps + 1:\n",
        "            raise ValueError(f'expanded lam length {len(lam)} != n_steps+1 ({n_steps+1})')\n",
        "        return lam\n",
        "\n",
        "    legacy_spec = parse_pattern_spec_legacy(pattern_raw)\n",
        "    expected_legacy = sum(ts for ts, _ in legacy_spec) + 1 if legacy_spec is not None else None\n",
        "    if expected_legacy is not None and len(lam_grouped) == expected_legacy:\n",
        "        lam = []\n",
        "        idx = 0\n",
        "        for ts, gs in legacy_spec:\n",
        "            for _ in range(ts):\n",
        "                lam.extend([lam_grouped[idx]] * gs)\n",
        "                idx += 1\n",
        "        lam.append(lam_grouped[-1])\n",
        "        if len(lam) != n_steps + 1:\n",
        "            raise ValueError(f'expanded legacy lam length {len(lam)} != n_steps+1 ({n_steps+1})')\n",
        "        return lam\n",
        "\n",
        "    raise ValueError(\n",
        "        f'grouped lam length {len(lam_grouped)} != expected_c {expected_c}'\n",
        "        + (f' and != expected_legacy {expected_legacy}' if expected_legacy is not None else '')\n",
        "    )\n",
        "\n",
        "\n",
        "def compute_t_grid(n_steps: int, t_max: float, alpha: float = 0.1):\n",
        "    beta = math.log(1 + t_max / alpha) / n_steps\n",
        "    t = [alpha * (math.exp(beta * k) - 1.0) for k in range(n_steps)]\n",
        "    t.append(float(t_max))\n",
        "    return np.asarray(t, dtype=float)\n",
        "\n",
        "\n",
        "def curve_from_json(path: Path):\n",
        "    d = json.loads(path.read_text())\n",
        "    theta = float(d['theta'])\n",
        "    mu = float(d.get('mu', MU))\n",
        "    n_steps = int(d['n_steps'])\n",
        "    t_max = float(d['t_max'])\n",
        "    bin_size = float(d.get('bin_size', WINDOW_BP))\n",
        "\n",
        "    pattern_raw = d.get('pattern')\n",
        "    pattern_spec = parse_pattern_spec(pattern_raw)\n",
        "    lam = np.asarray(expand_lam(d['lam'], n_steps, pattern_spec, pattern_raw=pattern_raw), dtype=float)\n",
        "\n",
        "    n0 = theta / (4.0 * mu * bin_size)\n",
        "    t = compute_t_grid(n_steps, t_max)\n",
        "\n",
        "    x = t * 2.0 * GEN_YEARS * n0\n",
        "    y = lam * n0\n",
        "\n",
        "    x = np.append(x, 1e8)\n",
        "    y = np.append(y, y[-1])\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def step_value(xs: np.ndarray, ys: np.ndarray, xq: float) -> float:\n",
        "    idx = np.searchsorted(xs, xq, side='right') - 1\n",
        "    idx = max(0, min(idx, len(ys) - 1))\n",
        "    return float(ys[idx])\n",
        "\n",
        "\n",
        "def rmse_log10(curve_a, curve_b, x_min=1e3, x_max=1e8, n=400):\n",
        "    xa, ya = curve_a\n",
        "    xb, yb = curve_b\n",
        "    grid = np.geomspace(x_min, x_max, n)\n",
        "    va = np.array([step_value(xa, ya, x) for x in grid])\n",
        "    vb = np.array([step_value(xb, yb, x) for x in grid])\n",
        "    m = (va > 0) & (vb > 0) & np.isfinite(va) & np.isfinite(vb)\n",
        "    if m.sum() == 0:\n",
        "        return float('nan')\n",
        "    return float(np.sqrt(np.mean((np.log10(va[m]) - np.log10(vb[m])) ** 2)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = []\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10), dpi=140)\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, key in enumerate(MODEL_ORDER):\n",
        "    ax = axes[i]\n",
        "    p = model_paths(key)\n",
        "\n",
        "    true_curve = true_curve_for_model(key)\n",
        "    psmcfa_curve = curve_from_json(p.rust_psmcfa_json)\n",
        "    mhs_curve = curve_from_json(p.rust_mhs_json)\n",
        "\n",
        "    tx, ty = true_curve\n",
        "    ax.step(tx, ty, where='post', lw=2.1, ls='--', color='dodgerblue', label='True')\n",
        "\n",
        "    x1, y1 = psmcfa_curve\n",
        "    x2, y2 = mhs_curve\n",
        "    ax.step(x1, y1, where='post', lw=2.0, color='tomato', label='PSMCFA input')\n",
        "    ax.step(x2, y2, where='post', lw=2.0, color='seagreen', label='MHS input')\n",
        "\n",
        "    ymax = max(float(np.max(ty)), float(np.max(y1)), float(np.max(y2)))\n",
        "    ax.set_title(MODELS[key]['title'])\n",
        "    ax.set_xscale('log')\n",
        "    ax.set_xlim(1e3, 1e8)\n",
        "    ax.set_ylim(0, ymax * 1.15)\n",
        "    ax.set_xlabel(f'Years (g={GEN_YEARS}, mu={MU:.1e})')\n",
        "    ax.set_ylabel('Effective population size (Ne)')\n",
        "    ax.grid(alpha=0.25)\n",
        "\n",
        "    metrics.append({\n",
        "        'model': key,\n",
        "        'rmse_log10_ne_vs_true_psmcfa': rmse_log10(true_curve, psmcfa_curve),\n",
        "        'rmse_log10_ne_vs_true_mhs': rmse_log10(true_curve, mhs_curve),\n",
        "        'rmse_log10_ne_mhs_vs_psmcfa': rmse_log10(mhs_curve, psmcfa_curve),\n",
        "    })\n",
        "\n",
        "handles, labels = axes[0].get_legend_handles_labels()\n",
        "fig.legend(handles, labels, loc='upper center', ncol=3, frameon=False)\n",
        "fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics).sort_values('model')\n",
        "run_pivot = run_df.pivot(index='model', columns='format', values='wall_sec').reset_index()\n",
        "summary_df = metrics_df.merge(run_pivot, on='model', how='left')\n",
        "summary_df['speed_ratio_mhs_over_psmcfa'] = summary_df['mhs'] / summary_df['psmcfa']\n",
        "\n",
        "print('Summary metrics (lower RMSE is better)')\n",
        "display(summary_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes\n",
        "\n",
        "- This is a **format comparison** under matched simulation and inference settings.\n",
        "- `MHS` and `PSMCFA` are generated from the **same simulated diploid genome** per model.\n",
        "- If runtime is too long on your machine, reduce `SIM_LENGTH_BP` (e.g., `5e7`) and rerun.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}